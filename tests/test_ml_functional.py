"""
Test ML Functional Validation

Verifies that ML components work correctly:
1. ML adapter initialization
2. Model loading
3. Feature extraction
4. ML ranking output format
5. Confidence threshold behavior
6. Fallback on errors
7. Constraint respect
8. Leads enhancement
9. Specialists enhancement
"""

import pytest
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, timedelta
from app.services.scheduling_engine import SchedulingEngine
from app.ml.inference.ml_scheduler_adapter import MLSchedulerAdapter
import os


class TestMLAdapterInitialization:
    """Test ML adapter initialization scenarios"""

    def test_ml_adapter_initialization_with_ml_enabled(self, app, db_session, models):
        """Test ML adapter initializes when ML is enabled"""
        with app.app_context():
            # Mock config with ML enabled
            with patch('app.services.scheduling_engine.current_app') as mock_app:
                mock_app.config = {
                    'ML_ENABLED': True,
                    'ML_EMPLOYEE_RANKING_ENABLED': True,
                    'ML_CONFIDENCE_THRESHOLD': 0.6,
                    'ML_EMPLOYEE_RANKER_PATH': 'app/ml/models/artifacts/employee_ranker_latest.pkl'
                }

                engine = SchedulingEngine(db_session, models)

                # Adapter should be initialized
                assert engine.ml_adapter is not None
                assert isinstance(engine.ml_adapter, MLSchedulerAdapter)

    def test_ml_adapter_initialization_with_ml_disabled(self, app, db_session, models):
        """Test ML adapter has use_ml=False when ML is disabled"""
        with app.app_context():
            with patch('app.services.scheduling_engine.current_app') as mock_app:
                mock_app.config = {
                    'ML_ENABLED': False
                }

                engine = SchedulingEngine(db_session, models)

                # Adapter is created (ML imports available) but use_ml should be False
                if engine.ml_adapter is not None:
                    assert engine.ml_adapter.use_ml is False
                else:
                    # ML imports not available â€” adapter is None, which is also fine
                    assert engine.ml_adapter is None

    def test_ml_adapter_configuration_flags(self, app, db_session, models):
        """Test ML adapter respects configuration flags"""
        with app.app_context():
            config = {
                'ML_ENABLED': True,
                'ML_EMPLOYEE_RANKING_ENABLED': True,
                'ML_BUMP_PREDICTION_ENABLED': False,
                'ML_CONFIDENCE_THRESHOLD': 0.7
            }

            adapter = MLSchedulerAdapter(db_session, models, config)

            assert adapter.use_ml is True
            assert adapter.use_employee_ranking is True
            assert adapter.use_bump_prediction is False
            assert adapter.confidence_threshold == 0.7


class TestModelLoading:
    """Test model loading scenarios"""

    def test_model_loading_lazy_initialization(self, app, db_session, models):
        """Test model uses lazy loading"""
        with app.app_context():
            config = {
                'ML_ENABLED': True,
                'ML_EMPLOYEE_RANKING_ENABLED': True,
                'ML_EMPLOYEE_RANKER_PATH': 'app/ml/models/artifacts/employee_ranker_latest.pkl'
            }

            adapter = MLSchedulerAdapter(db_session, models, config)

            # Model should not be loaded yet
            assert adapter._employee_ranker is None

            # Access property to trigger loading
            if os.path.exists(config['ML_EMPLOYEE_RANKER_PATH']):
                model = adapter.employee_ranker
                assert model is not None
            else:
                # If model doesn't exist, should return None gracefully
                model = adapter.employee_ranker
                assert model is None

    def test_model_loading_failure_handling(self, app, db_session, models):
        """Test graceful handling of model loading failures"""
        with app.app_context():
            config = {
                'ML_ENABLED': True,
                'ML_EMPLOYEE_RANKING_ENABLED': True,
                'ML_EMPLOYEE_RANKER_PATH': '/nonexistent/path/model.pkl'
            }

            adapter = MLSchedulerAdapter(db_session, models, config)

            # Should handle missing model gracefully
            model = adapter.employee_ranker
            assert model is None


class TestFeatureExtraction:
    """Test feature extraction for ML models"""

    def test_feature_extraction_for_employee(self, app, db_session, models):
        """Test extracting features for an employee"""
        with app.app_context():
            Employee = models['Employee']
            Event = models['Event']

            # Create test employee
            employee = Employee(
                id='test_emp',
                name='Test Employee',
                job_title='Lead Event Specialist',
                is_active=True
            )
            db_session.add(employee)
            db_session.commit()

            # Create test event
            start = datetime.now() + timedelta(days=7)
            event = Event(
                project_name='Test Project',
                project_ref_num=1000,
                event_type='Core',
                is_scheduled=False,
                estimated_time=2.0,
                start_datetime=start,
                due_datetime=start + timedelta(days=7)
            )
            db_session.add(event)
            db_session.commit()

            config = {
                'ML_ENABLED': True,
                'ML_EMPLOYEE_RANKING_ENABLED': True
            }

            adapter = MLSchedulerAdapter(db_session, models, config)

            # Test feature extraction
            try:
                features = adapter.employee_features.extract(employee, event, datetime.now())

                # Verify expected features exist
                assert 'role_numeric' in features
                assert 'is_active' in features
                assert 'current_week_assignments' in features

                # Features should be numeric
                assert all(isinstance(v, (int, float)) for v in features.values())
            except Exception as e:
                # If feature extraction not fully implemented, that's okay for now
                pytest.skip(f"Feature extraction not fully implemented: {e}")


class TestMLRankingOutput:
    """Test ML ranking output format"""

    def test_rank_employees_output_format(self, app, db_session, models):
        """Test that rank_employees returns correct format"""
        with app.app_context():
            Employee = models['Employee']
            Event = models['Event']

            # Create test employees
            employees = [
                Employee(id=f'emp_{i}', name=f'Employee {i}', job_title='Lead Event Specialist', is_active=True)
                for i in range(3)
            ]
            for emp in employees:
                db_session.add(emp)
            db_session.commit()

            # Create test event
            start = datetime.now() + timedelta(days=7)
            event = Event(
                project_name='Test Project',
                project_ref_num=1001,
                event_type='Core',
                is_scheduled=False,
                estimated_time=2.0,
                start_datetime=start,
                due_datetime=start + timedelta(days=7)
            )
            db_session.add(event)
            db_session.commit()

            config = {
                'ML_ENABLED': True,
                'ML_EMPLOYEE_RANKING_ENABLED': True
            }

            adapter = MLSchedulerAdapter(db_session, models, config)

            # Rank employees
            ranked = adapter.rank_employees(employees, event, datetime.now())

            # Should return list of tuples (employee, confidence)
            assert isinstance(ranked, list)
            assert len(ranked) <= len(employees)

            if ranked:
                assert isinstance(ranked[0], tuple)
                assert len(ranked[0]) == 2
                employee, confidence = ranked[0]
                assert isinstance(employee, Employee)
                assert isinstance(confidence, float)
                assert 0 <= confidence <= 1

    def test_rank_employees_ordering(self, app, db_session, models):
        """Test that ranked employees are ordered by confidence descending"""
        with app.app_context():
            Employee = models['Employee']
            Event = models['Event']

            employees = [
                Employee(id=f'emp_{i}', name=f'Employee {i}', job_title='Lead Event Specialist', is_active=True)
                for i in range(5)
            ]
            for emp in employees:
                db_session.add(emp)
            db_session.commit()

            start = datetime.now() + timedelta(days=7)
            event = Event(
                project_name='Test Project',
                project_ref_num=1002,
                event_type='Core',
                is_scheduled=False,
                start_datetime=start,
                due_datetime=start + timedelta(days=7)
            )
            db_session.add(event)
            db_session.commit()

            config = {'ML_ENABLED': True, 'ML_EMPLOYEE_RANKING_ENABLED': True}
            adapter = MLSchedulerAdapter(db_session, models, config)

            ranked = adapter.rank_employees(employees, event, datetime.now())

            if len(ranked) > 1:
                # Confidences should be descending
                confidences = [conf for _, conf in ranked]
                assert confidences == sorted(confidences, reverse=True)


class TestConfidenceThreshold:
    """Test confidence threshold behavior"""

    def test_low_confidence_filtering(self, app, db_session, models):
        """Test that low confidence predictions trigger fallback"""
        with app.app_context():
            Employee = models['Employee']
            Event = models['Event']

            employees = [
                Employee(id=f'emp_{i}', name=f'Employee {i}', job_title='Specialist', is_active=True)
                for i in range(3)
            ]
            for emp in employees:
                db_session.add(emp)
            db_session.commit()

            start = datetime.now() + timedelta(days=7)
            event = Event(project_name='Test', project_ref_num=1003, event_type='Core', is_scheduled=False, start_datetime=start, due_datetime=start + timedelta(days=7))
            db_session.add(event)
            db_session.commit()

            # Set high confidence threshold to force fallback
            config = {
                'ML_ENABLED': True,
                'ML_EMPLOYEE_RANKING_ENABLED': True,
                'ML_CONFIDENCE_THRESHOLD': 0.99  # Unrealistically high
            }

            adapter = MLSchedulerAdapter(db_session, models, config)
            ranked = adapter.rank_employees(employees, event, datetime.now())

            # Should still return employees (via fallback)
            assert len(ranked) > 0
            assert adapter.fallbacks_triggered >= 0  # Stats tracked


class TestFallbackOnError:
    """Test graceful fallback on errors"""

    def test_fallback_on_prediction_error(self, app, db_session, models):
        """Test fallback when ML prediction fails"""
        with app.app_context():
            Employee = models['Employee']
            Event = models['Event']

            employees = [
                Employee(id='test_emp', name='Test Employee', job_title='Specialist', is_active=True)
            ]
            for emp in employees:
                db_session.add(emp)
            db_session.commit()

            start = datetime.now() + timedelta(days=7)
            event = Event(project_name='Test', project_ref_num=1004, event_type='Core', is_scheduled=False, start_datetime=start, due_datetime=start + timedelta(days=7))
            db_session.add(event)
            db_session.commit()

            config = {'ML_ENABLED': True, 'ML_EMPLOYEE_RANKING_ENABLED': True}
            adapter = MLSchedulerAdapter(db_session, models, config)

            # Mock ML prediction to raise exception
            with patch.object(adapter, '_ml_rank_employees', side_effect=Exception("Model error")):
                ranked = adapter.rank_employees(employees, event, datetime.now())

                # Should fallback to rule-based ranking
                assert len(ranked) > 0
                assert adapter.fallbacks_triggered > 0


class TestConstraintRespect:
    """Test that ML respects constraint validation"""

    def test_ml_only_ranks_constraint_valid_employees(self, app, db_session, models):
        """Test that ML only ranks employees who pass constraint validation"""
        with app.app_context():
            # This test verifies the integration pattern:
            # SchedulingEngine should filter by constraints BEFORE calling ML

            # The ML adapter itself doesn't validate constraints
            # It assumes the input list is already filtered
            # This is tested in integration tests with SchedulingEngine

            # Here we just verify the adapter accepts any list
            Employee = models['Employee']
            Event = models['Event']

            employees = [
                Employee(id='avail_emp', name='Available', job_title='Specialist', is_active=True),
                Employee(id='unavail_emp', name='Unavailable', job_title='Specialist', is_active=False)
            ]
            for emp in employees:
                db_session.add(emp)
            db_session.commit()

            start = datetime.now() + timedelta(days=7)
            event = Event(project_name='Test', project_ref_num=1005, event_type='Core', is_scheduled=False, start_datetime=start, due_datetime=start + timedelta(days=7))
            db_session.add(event)
            db_session.commit()

            config = {'ML_ENABLED': True, 'ML_EMPLOYEE_RANKING_ENABLED': True}
            adapter = MLSchedulerAdapter(db_session, models, config)

            # Adapter should rank whatever list it's given
            ranked = adapter.rank_employees(employees, event, datetime.now())

            # Both employees should be ranked (no filtering in adapter)
            assert len(ranked) == len(employees)


class TestSchedulingEngineIntegration:
    """Test SchedulingEngine integration with ML"""

    def test_get_available_leads_uses_ml(self, app, db_session, models):
        """Test that _get_available_leads uses ML when enabled"""
        with app.app_context():
            Employee = models['Employee']
            Event = models['Event']

            # Create lead employees
            leads = [
                Employee(id=f'lead_{i}', name=f'Lead {i}', job_title='Lead Event Specialist', is_active=True)
                for i in range(3)
            ]
            for lead in leads:
                db_session.add(lead)
            db_session.commit()

            start = datetime.now() + timedelta(days=7)
            event = Event(project_name='Test', project_ref_num=1006, event_type='Core', is_scheduled=False, start_datetime=start, due_datetime=start + timedelta(days=7))
            db_session.add(event)
            db_session.commit()

            with patch('app.services.scheduling_engine.current_app') as mock_app:
                mock_app.config = {
                    'ML_ENABLED': True,
                    'ML_EMPLOYEE_RANKING_ENABLED': True,
                    'ML_CONFIDENCE_THRESHOLD': 0.6
                }

                engine = SchedulingEngine(db_session, models)

                # Call should work with or without ML
                available_leads = engine._get_available_leads(event, datetime.now())

                # Should return a list (possibly empty)
                assert isinstance(available_leads, list)

    def test_get_available_specialists_uses_ml(self, app, db_session, models):
        """Test that _get_available_specialists uses ML when enabled"""
        with app.app_context():
            Employee = models['Employee']
            Event = models['Event']

            specialists = [
                Employee(id=f'spec_{i}', name=f'Specialist {i}', job_title='Specialist', is_active=True)
                for i in range(3)
            ]
            for spec in specialists:
                db_session.add(spec)
            db_session.commit()

            start = datetime.now() + timedelta(days=7)
            event = Event(project_name='Test', project_ref_num=1007, event_type='Core', is_scheduled=False, start_datetime=start, due_datetime=start + timedelta(days=7))
            db_session.add(event)
            db_session.commit()

            with patch('app.services.scheduling_engine.current_app') as mock_app:
                mock_app.config = {
                    'ML_ENABLED': True,
                    'ML_EMPLOYEE_RANKING_ENABLED': True
                }

                engine = SchedulingEngine(db_session, models)

                available_specialists = engine._get_available_specialists(event, datetime.now())

                assert isinstance(available_specialists, list)


class TestMLAdapterStatistics:
    """Test ML adapter statistics tracking"""

    def test_get_stats_returns_correct_format(self, app, db_session, models):
        """Test that get_stats returns expected statistics"""
        with app.app_context():
            config = {'ML_ENABLED': True, 'ML_EMPLOYEE_RANKING_ENABLED': True}
            adapter = MLSchedulerAdapter(db_session, models, config)

            stats = adapter.get_stats()

            assert isinstance(stats, dict)
            assert 'predictions_made' in stats
            assert 'fallbacks_triggered' in stats
            assert 'ml_enabled' in stats
            assert 'employee_ranking_enabled' in stats

    def test_reset_stats_clears_counters(self, app, db_session, models):
        """Test that reset_stats clears prediction counters"""
        with app.app_context():
            config = {'ML_ENABLED': True, 'ML_EMPLOYEE_RANKING_ENABLED': True}
            adapter = MLSchedulerAdapter(db_session, models, config)

            # Increment counters
            adapter.predictions_made = 10
            adapter.fallbacks_triggered = 5

            # Reset
            adapter.reset_stats()

            assert adapter.predictions_made == 0
            assert adapter.fallbacks_triggered == 0
